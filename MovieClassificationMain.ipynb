{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of High rated movie, if IMDB rating greater than 8\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      1775\n",
      "        1.0       0.44      0.07      0.12       103\n",
      "\n",
      "avg / total       0.92      0.94      0.92      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      1775\n",
      "        1.0       0.94      0.89      0.92       103\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      1775\n",
      "        1.0       1.00      1.00      1.00       103\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1775\n",
      "        1.0       0.95      0.69      0.80       103\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      1775\n",
      "        1.0       1.00      1.00      1.00       103\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.96      0.96      1775\n",
      "        1.0       0.24      0.23      0.24       103\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 1.0\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 1.0\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.937833219412\n",
      "vectorization Recall= 0.7357696567\n",
      "vectorization F1= 0.880263736264\n",
      "------------Random Forest method\n",
      "vectorization Precision= 1.0\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 1.0\n",
      "------------Logistic regrassion  l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization Precision= 0.472759856631\n",
      "vectorization Recall= 0.116832779623\n",
      "vectorization F1= 0.166894201894\n",
      "------------Logistic regrassion  l1\n",
      "vectorization Precision= 0.960941576858\n",
      "vectorization Recall= 0.929457364341\n",
      "vectorization F1= 0.945369952859\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.328879015721\n",
      "vectorization Recall= 0.323145071982\n",
      "vectorization F1= 0.243923974083\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.94      0.95      1770\n",
      "        1.0       0.33      0.51      0.40       108\n",
      "\n",
      "avg / total       0.93      0.91      0.92      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      1770\n",
      "        1.0       0.84      0.67      0.74       108\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.98      0.97      1770\n",
      "        1.0       0.56      0.53      0.55       108\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      1770\n",
      "        1.0       0.85      0.27      0.41       108\n",
      "\n",
      "avg / total       0.95      0.96      0.94      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      1770\n",
      "        1.0       0.87      0.31      0.46       108\n",
      "\n",
      "avg / total       0.95      0.96      0.95      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.95      0.96      1770\n",
      "        1.0       0.44      0.64      0.52       108\n",
      "\n",
      "avg / total       0.95      0.93      0.94      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 0.513515970587\n",
      "vectorization Recall= 0.541638981174\n",
      "vectorization F1= 0.486762043359\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.842809364548\n",
      "vectorization Recall= 0.272093023256\n",
      "vectorization F1= 0.352025143483\n",
      "------------Random Forest method\n",
      "vectorization Precision= 0.852461456672\n",
      "vectorization Recall= 0.41838316722\n",
      "vectorization F1= 0.494061938152\n",
      "------------Logistic regrassion  l2\n",
      "vectorization Precision= 0.546199353482\n",
      "vectorization Recall= 0.530897009967\n",
      "vectorization F1= 0.400261183076\n",
      "------------Logistic regrassion  l1\n",
      "vectorization Precision= 0.805997631401\n",
      "vectorization Recall= 0.62569213732\n",
      "vectorization F1= 0.670113724505\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.489700782626\n",
      "vectorization Recall= 0.591915836102\n",
      "vectorization F1= 0.463527966321\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of High rated movie, if IMDB rating greater than 8\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'imdb_score'\n",
    "list_fig = ['director_facebook_likes','gross','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster','profit']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "print(\"Classification of High rated movie, if IMDB rating greater than 8\")\n",
    "\n",
    "cut_off = 8\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "\n",
    "# Adding text features\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x_all, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of profitable movie, if gross is greater than budget\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       864\n",
      "        1.0       1.00      1.00      1.00      1014\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99       864\n",
      "        1.0       1.00      0.98      0.99      1014\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95       864\n",
      "        1.0       0.96      0.95      0.95      1014\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.88      0.84       864\n",
      "        1.0       0.89      0.82      0.85      1014\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.91      0.90       864\n",
      "        1.0       0.92      0.91      0.91      1014\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      0.81      0.73       864\n",
      "        1.0       0.80      0.65      0.72      1014\n",
      "\n",
      "avg / total       0.73      0.72      0.72      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 0.876073530321\n",
      "vectorization Recall= 0.909190968725\n",
      "vectorization F1= 0.888611341941\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.866136956331\n",
      "vectorization Recall= 0.840203424809\n",
      "vectorization F1= 0.823856337733\n",
      "------------Random Forest method\n",
      "vectorization Precision= 0.880924950858\n",
      "vectorization Recall= 0.79258162789\n",
      "vectorization F1= 0.845127995924\n",
      "------------Logistic regrassion  l2\n",
      "vectorization Precision= 0.99900990099\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 0.999504337051\n",
      "------------Logistic regrassion  l1\n",
      "vectorization Precision= 0.99802952061\n",
      "vectorization Recall= 0.993548387097\n",
      "vectorization F1= 0.995754437487\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.671590980113\n",
      "vectorization Recall= 0.699255583127\n",
      "vectorization F1= 0.595951370005\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.65      0.66       863\n",
      "        1.0       0.71      0.74      0.73      1015\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.75      0.71       863\n",
      "        1.0       0.77      0.70      0.73      1015\n",
      "\n",
      "avg / total       0.73      0.72      0.72      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.63      0.62       863\n",
      "        1.0       0.68      0.66      0.67      1015\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.73      0.67       863\n",
      "        1.0       0.73      0.64      0.68      1015\n",
      "\n",
      "avg / total       0.69      0.68      0.68      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.74      0.69       863\n",
      "        1.0       0.75      0.65      0.70      1015\n",
      "\n",
      "avg / total       0.70      0.69      0.69      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.54      0.75      0.63       863\n",
      "        1.0       0.68      0.47      0.56      1015\n",
      "\n",
      "avg / total       0.62      0.60      0.59      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 0.660651605011\n",
      "vectorization Recall= 0.628005306734\n",
      "vectorization F1= 0.632843410518\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.72121774791\n",
      "vectorization Recall= 0.662651401617\n",
      "vectorization F1= 0.673667922268\n",
      "------------Random Forest method\n",
      "vectorization Precision= 0.723501062846\n",
      "vectorization Recall= 0.64045647741\n",
      "vectorization F1= 0.68723285018\n",
      "------------Logistic regrassion  l2\n",
      "vectorization Precision= 0.715130518264\n",
      "vectorization Recall= 0.729765619242\n",
      "vectorization F1= 0.710613608677\n",
      "------------Logistic regrassion  l1\n",
      "vectorization Precision= 0.745273102134\n",
      "vectorization Recall= 0.716805886544\n",
      "vectorization F1= 0.7287550219\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.66349573163\n",
      "vectorization Recall= 0.569975186104\n",
      "vectorization F1= 0.538751466857\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of profitable movie, if gross is greater than budget\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):    \n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'gross'\n",
    "list_fig = ['director_facebook_likes','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "y = data['profit']\n",
    "print(\"Classification of profitable movie, if gross is greater than budget\")\n",
    "\n",
    "cut_off = 0\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "# Adding text features\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x_all, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
