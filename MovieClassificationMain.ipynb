{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of High rated movie, if IMDB rating greater than 8\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      1785\n",
      "        1.0       0.65      0.12      0.20        93\n",
      "\n",
      "avg / total       0.94      0.95      0.94      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      1785\n",
      "        1.0       0.91      0.86      0.88        93\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      1785\n",
      "        1.0       1.00      1.00      1.00        93\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      1785\n",
      "        1.0       0.92      0.49      0.64        93\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      1785\n",
      "        1.0       1.00      1.00      1.00        93\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Logit method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.98      1785\n",
      "        1.0       0.59      0.18      0.28        93\n",
      "\n",
      "avg / total       0.94      0.95      0.94      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.94      0.95      1785\n",
      "        1.0       0.24      0.33      0.28        93\n",
      "\n",
      "avg / total       0.93      0.91      0.92      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 1.0\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 1.0\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.941282296651\n",
      "vectorization Recall= 0.735548172757\n",
      "vectorization F1= 0.762756929713\n",
      "------------Random Forest method\n",
      "vectorization Precision= 1.0\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 1.0\n",
      "------------Logit method\n",
      "vectorization Precision= 0.348731599113\n",
      "vectorization Recall= 0.178073089701\n",
      "vectorization F1= 0.222080801131\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.328879015721\n",
      "vectorization Recall= 0.323145071982\n",
      "vectorization F1= 0.243923974083\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.95      0.96      1779\n",
      "        1.0       0.35      0.53      0.42        99\n",
      "\n",
      "avg / total       0.94      0.92      0.93      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1779\n",
      "        1.0       0.82      0.57      0.67        99\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.98      0.97      1779\n",
      "        1.0       0.52      0.48      0.50        99\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      1779\n",
      "        1.0       0.85      0.28      0.42        99\n",
      "\n",
      "avg / total       0.96      0.96      0.95      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.98      1779\n",
      "        1.0       0.79      0.33      0.47        99\n",
      "\n",
      "avg / total       0.95      0.96      0.95      1878\n",
      "\n",
      "------------Logit method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.95      0.96      1779\n",
      "        1.0       0.34      0.51      0.41        99\n",
      "\n",
      "avg / total       0.94      0.92      0.93      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.95      0.97      1779\n",
      "        1.0       0.41      0.58      0.48        99\n",
      "\n",
      "avg / total       0.95      0.93      0.94      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of High rated movie, if IMDB rating greater than 8\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'imdb_score'\n",
    "list_fig = ['director_facebook_likes','gross','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster','profit']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "print(\"Classification of High rated movie, if IMDB rating greater than 8\")\n",
    "\n",
    "cut_off = 8\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "\n",
    "# Adding text features\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of profitable movie, if gross is greater than budget\n",
      "------------Naïve Bayes\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       849\n",
      "        1.0       1.00      1.00      1.00      1029\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       849\n",
      "        1.0       1.00      1.00      1.00      1029\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakther\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99       849\n",
      "        1.0       1.00      0.99      1.00      1029\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.95      0.95       849\n",
      "        1.0       0.96      0.96      0.96      1029\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.89      0.85       849\n",
      "        1.0       0.90      0.83      0.86      1029\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.91      0.89       849\n",
      "        1.0       0.93      0.89      0.91      1029\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1878\n",
      "\n",
      "------------SVC method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.02      0.05       849\n",
      "        1.0       0.55      1.00      0.71      1029\n",
      "\n",
      "avg / total       0.76      0.56      0.41      1878\n",
      "\n",
      "------------Logit method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       849\n",
      "        1.0       1.00      1.00      1.00      1029\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.87      0.69       849\n",
      "        1.0       0.81      0.47      0.59      1029\n",
      "\n",
      "avg / total       0.70      0.65      0.64      1878\n",
      "\n",
      "---------Naïve Bayes  --------------\n",
      "vectorization Precision= 0.930062959249\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 0.962976948771\n",
      "------------Decision Tree method\n",
      "vectorization Precision= 0.866532735636\n",
      "vectorization Recall= 0.907209542294\n",
      "vectorization F1= 0.887058542538\n",
      "------------Extra Trees method\n",
      "vectorization Precision= 0.877133376692\n",
      "vectorization Recall= 0.814409257303\n",
      "vectorization F1= 0.826790233008\n",
      "------------Random Forest method\n",
      "vectorization Precision= 0.861132235057\n",
      "vectorization Recall= 0.815912831978\n",
      "vectorization F1= 0.855005643617\n",
      "------------SVC method\n",
      "vectorization Precision= 0.5448760186\n",
      "vectorization Recall= 1.0\n",
      "vectorization F1= 0.705394160977\n",
      "------------Logit method\n",
      "vectorization Precision= 0.999504950495\n",
      "vectorization Recall= 0.999007444169\n",
      "vectorization F1= 0.999255274115\n",
      "------------GaussianNaiveBayes method\n",
      "vectorization Precision= 0.671590980113\n",
      "vectorization Recall= 0.699255583127\n",
      "vectorization F1= 0.595951370005\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Naïve Bayes\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.65      0.64       863\n",
      "        1.0       0.70      0.70      0.70      1015\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1878\n",
      "\n",
      "------------Logistic regrassion  l2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.64      0.66       863\n",
      "        1.0       0.71      0.76      0.73      1015\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1878\n",
      "\n",
      "------------Logistic regrassion  l1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.71      0.71       863\n",
      "        1.0       0.75      0.75      0.75      1015\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1878\n",
      "\n",
      "------------Decision Tree method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.59      0.61       863\n",
      "        1.0       0.67      0.70      0.68      1015\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1878\n",
      "\n",
      "------------Extra Trees method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.69      0.67       863\n",
      "        1.0       0.72      0.68      0.70      1015\n",
      "\n",
      "avg / total       0.69      0.68      0.69      1878\n",
      "\n",
      "------------Random Forest method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.70      0.67       863\n",
      "        1.0       0.72      0.67      0.69      1015\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1878\n",
      "\n",
      "------------SVC method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.02      0.05       863\n",
      "        1.0       0.55      1.00      0.71      1015\n",
      "\n",
      "avg / total       0.75      0.55      0.40      1878\n",
      "\n",
      "------------Logit method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.62      0.65       863\n",
      "        1.0       0.70      0.76      0.73      1015\n",
      "\n",
      "avg / total       0.70      0.70      0.69      1878\n",
      "\n",
      "------------GaussianNaiveBayes method\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.69      0.61       863\n",
      "        1.0       0.66      0.52      0.58      1015\n",
      "\n",
      "avg / total       0.61      0.60      0.60      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of profitable movie, if gross is greater than budget\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):    \n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'gross'\n",
    "list_fig = ['director_facebook_likes','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "y = data['profit']\n",
    "print(\"Classification of profitable movie, if gross is greater than budget\")\n",
    "\n",
    "cut_off = 0\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "# Adding text features\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
