{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['indices', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAERCAYAAAB1k2wJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR9wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x314fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Square Error "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\Lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.013732\n",
      "dtype: float64\n",
      "R-Square: 0.297677370148\n",
      "correlation with director_facebook_likes is: 0.192313548643\n",
      "correlation with gross is: 0.214739712176\n",
      "correlation with num_voted_users is: 0.482429606479\n",
      "correlation with num_critic_for_reviews is: 0.347885638604\n",
      "correlation with num_user_for_reviews is: 0.325002592496\n",
      "correlation with budget is: 0.0291897224546\n",
      "correlation with movie_facebook_likes is: 0.281154991472\n",
      "correlation with duration is: 0.366221017357\n",
      "correlation with actor_3_facebook_likes is: 0.0655436116815\n",
      "correlation with actor_1_facebook_likes is: 0.0935971797263\n",
      "correlation with actor_2_facebook_likes is: 0.102372039041\n",
      "correlation with cast_total_facebook_likes is: 0.106802526649\n",
      "correlation with facenumber_in_poster is: -0.0654926113212\n",
      "correlation with profit is: 0.0369819844511\n",
      "In the movie data, 642 out of 3756 directors_facebook_like are 0\n",
      "In the movie data, 1742 out of 3756 movie_facebook_like are 0\n",
      "Minimum Square Error with few numeric 0    0.012694\n",
      "dtype: float64\n",
      "R-Square with few numeric: 0.319519006831\n",
      "Minimum Square Error with numeric+text 0    0.010179\n",
      "dtype: float64\n",
      "R-Square with numeric+text: 0.443234133458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.143e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.689e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.870e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.537e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.163e-04, with an active set of 54 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.163e-04, with an active set of 54 regressors, and the smallest cholesky pivot element being 9.714e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=8.041e-04, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=7.777e-04, with an active set of 60 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=7.719e-04, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=7.713e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 7.146e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.178e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 7.224e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.178e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 7.146e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.178e-04, with an active set of 70 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=6.514e-04, with an active set of 82 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=6.491e-04, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.224e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.118e-04, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=5.953e-04, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=5.843e-04, with an active set of 112 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=5.820e-04, with an active set of 114 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=5.796e-04, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.689e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=5.796e-04, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.679e-04, with an active set of 122 regressors, and the smallest cholesky pivot element being 7.146e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=5.480e-04, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=5.480e-04, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=5.433e-04, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=5.308e-04, with an active set of 140 regressors, and the smallest cholesky pivot element being 5.373e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=5.297e-04, with an active set of 143 regressors, and the smallest cholesky pivot element being 8.689e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.956e-04, with an active set of 165 regressors, and the smallest cholesky pivot element being 5.960e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=4.865e-04, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=4.714e-04, with an active set of 187 regressors, and the smallest cholesky pivot element being 6.409e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 188 iterations, i.e. alpha=4.688e-04, with an active set of 188 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=4.612e-04, with an active set of 197 regressors, and the smallest cholesky pivot element being 7.068e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=4.599e-04, with an active set of 198 regressors, and the smallest cholesky pivot element being 9.064e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=4.599e-04, with an active set of 198 regressors, and the smallest cholesky pivot element being 3.161e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=4.509e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=4.499e-04, with an active set of 208 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=4.493e-04, with an active set of 208 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.421e-04, with an active set of 215 regressors, and the smallest cholesky pivot element being 8.560e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.362e-04, with an active set of 223 regressors, and the smallest cholesky pivot element being 3.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.287e-04, with an active set of 229 regressors, and the smallest cholesky pivot element being 9.828e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.287e-04, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.495e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.287e-04, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.287e-04, with an active set of 229 regressors, and the smallest cholesky pivot element being 6.322e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.276e-04, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=4.262e-04, with an active set of 235 regressors, and the smallest cholesky pivot element being 5.674e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.251e-04, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.251e-04, with an active set of 238 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=4.211e-04, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=4.193e-04, with an active set of 246 regressors, and the smallest cholesky pivot element being 7.068e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.047e-04, with an active set of 266 regressors, and the smallest cholesky pivot element being 7.376e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.038e-04, with an active set of 268 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.038e-04, with an active set of 268 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.972e-04, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 278 iterations, i.e. alpha=3.972e-04, with an active set of 278 regressors, and the smallest cholesky pivot element being 4.215e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=3.948e-04, with an active set of 284 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.924e-04, with an active set of 287 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.924e-04, with an active set of 287 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=3.840e-04, with an active set of 300 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=3.840e-04, with an active set of 300 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 301 iterations, alpha=3.842e-04, previous alpha=3.840e-04, with an active set of 302 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00038422216645\n",
      "Rsq Lasso:  0.440971247916\n",
      "CV score for LASSO:  0.40024119033\n",
      "CV score for RF:  0.507358059293\n",
      "R square for RF:  0.542021764496\n",
      "['num_voted_users', u'genres_drama', 'budget', 'duration', 'gross', 'num_user_for_reviews', 'num_critic_for_reviews', 'actor_3_facebook_likes', 'actor_2_facebook_likes', 'director_facebook_likes']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAFRCAYAAAALn8i+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn+M4jtOpcOFzHMdxOhX/H0gtNwVWXS9LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1625c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Author - Soujanya\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import Preprocessor\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "%pylab inline\n",
    "#Reading from csv and Cleaning\n",
    "imdb_movie = Preprocessor.data\n",
    "imdb_movie['profit'] = imdb_movie['gross'] - imdb_movie['budget']\n",
    "\n",
    "print len(imdb_movie)\n",
    "\n",
    "##################################\n",
    "#Plotting histogram for imdb_score\n",
    "##################################\n",
    "\n",
    "imdb_score = imdb_movie['imdb_score']\n",
    "plt.hist(imdb_score,bins=20)\n",
    "plt.xlabel('IMDB score')\n",
    "plt.show()\n",
    "\n",
    "list_fig = ['director_facebook_likes','gross','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster','profit']\n",
    "\n",
    "data,target = Preprocessor.getX_y(targetColumn='imdb_score',featureColumns=list_fig)\n",
    "targetcol = 'imdb_score'\n",
    "\n",
    "data,target = scaler(data,target)\n",
    "\n",
    "###################\n",
    "#Correlation Plot\n",
    "###################\n",
    "# corr = data.select_dtypes(include = ['float64', 'int64']).iloc[:, 1:].corr()\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# sns.heatmap(corr, vmax=1, square=True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size=0.75)\n",
    "\n",
    "###########################################\n",
    "#First step: Using Simple Linear Regression\n",
    "###########################################\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "mse = np.mean((pred - ytest) ** 2)\n",
    "print 'Minimum Square Error', mse\n",
    "print 'R-Square:', model.score(xtest,ytest)\n",
    "\n",
    "###############\n",
    "# Scatter plots\n",
    "###############\n",
    "\n",
    "# plt.figure(figsize=(7,10))\n",
    "# for i in range(len(list_fig)):\n",
    "#     plt.subplot(8,2,i+1)\n",
    "#     plt.title(list_fig[i])\n",
    "#     plt.scatter(target,data[list_fig[i]],marker='x',color='r',label='dir_score')    \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "for i in list_fig:\n",
    "    corre = np.corrcoef(imdb_movie[i],imdb_movie['imdb_score'])\n",
    "    print 'correlation with', i , 'is:', corre[0][1]\n",
    "\n",
    "#------------------------------------------------\n",
    "imdb_movie_dir = imdb_movie[imdb_movie['director_facebook_likes']==0]\n",
    "print 'In the movie data,',imdb_movie_dir.shape[0],'out of', imdb_movie.shape[0],'directors_facebook_like are 0'\n",
    "\n",
    "imdb_movie_ml = imdb_movie[imdb_movie['movie_facebook_likes']==0]\n",
    "print 'In the movie data,',imdb_movie_ml.shape[0],'out of', imdb_movie.shape[0],'movie_facebook_like are 0'\n",
    "\n",
    "#############################################\n",
    "#Second Step: Removing Few Numerical Features\n",
    "#############################################\n",
    "\n",
    "remove_list = ['director_facebook_likes','movie_facebook_likes']\n",
    "for rm in remove_list:\n",
    "    list_fig.remove(rm)\n",
    "\n",
    "data,target = Preprocessor.getX_y(targetColumn='imdb_score',featureColumns=list_fig)\n",
    "targetcol = 'imdb_score'\n",
    "\n",
    "data,target = scaler(data,target)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size=0.75)\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(xtrain,ytrain)\n",
    "pred = model_2.predict(xtest)\n",
    "mse2 = np.mean((pred - ytest) ** 2)\n",
    "print 'Minimum Square Error with few numeric', mse2\n",
    "print 'R-Square with few numeric:', model_2.score(xtest,ytest)\n",
    "    \n",
    "###############################################\n",
    "#Third step: Including text/categorical feature\n",
    "###############################################\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(imdb_movie['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(imdb_movie['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(imdb_movie['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "new_data = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "new_coeff_list = list_fig+genres_list+pk_list+c_list\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(new_data,target,train_size=0.5)\n",
    "\n",
    "model_3 = LinearRegression()\n",
    "model_3.fit(xtrain,ytrain)\n",
    "pred = model_3.predict(xtest)\n",
    "mse3 = np.mean((pred - ytest) ** 2)\n",
    "print 'Minimum Square Error with numeric+text', mse3\n",
    "print 'R-Square with numeric+text:', model_3.score(xtest,ytest)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.scatter(pred , ytest)\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.xlabel(\"fitted value\")\n",
    "plt.ylabel(\"actual value\")\n",
    "\n",
    "####################################\n",
    "#Using LASSO Regression\n",
    "####################################\n",
    "\n",
    "list_fig = ['director_facebook_likes','gross','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster','profit']\n",
    "\n",
    "# data,target = Preprocessor.getX_y(targetColumn='imdb_score',featureColumns=list_fig)\n",
    "# targetcol = 'imdb_score'\n",
    "\n",
    "# data,target = scaler(data,target)\n",
    "\n",
    "data = imdb_movie[list_fig]\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "target = imdb_movie['imdb_score']\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(imdb_movie['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(imdb_movie['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(imdb_movie['director_name'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "new_data = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "new_coeff_list = list_fig+genres_list+pk_list+c_list\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(new_data,target,train_size=0.75)\n",
    "\n",
    "aic_m = LassoLarsIC(criterion='aic')\n",
    "aic_m.fit(xtrain, ytrain)\n",
    "alphas_ = aic_m.alphas_\n",
    "criterion_ = aic_m.criterion_\n",
    "# plt.subplot(224)\n",
    "# plt.plot(-np.log10(alphas_), criterion_, '--', color='b',\n",
    "#              linewidth=3)\n",
    "# plt.show()\n",
    "print aic_m.alpha_\n",
    "\n",
    "model_L = Lasso(alpha=aic_m.alpha_)\n",
    "model_L.fit(xtrain,ytrain)\n",
    "ypred = model_L.predict(xtest)\n",
    "score = cross_val_score(model_L, new_data, target,cv=5)\n",
    "mse2 = (np.mean((ypred - ytest) ** 2))\n",
    "rsq = model_L.score(xtest,ytest)\n",
    "\n",
    "print 'Rsq Lasso: ', rsq\n",
    "print 'CV score for LASSO: ',np.mean(score)\n",
    "\n",
    "########################################\n",
    "#Using Random Forest Regression\n",
    "########################################\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(xtrain, ytrain)\n",
    "scores = cross_val_score(rf,new_data,target,cv=5)\n",
    "print 'CV score for RF: ',np.mean(scores)\n",
    "pred_rf = rf.predict(xtest)\n",
    "mse4 = np.mean((pred_rf - ytest) ** 2)\n",
    "rsq1 = rf.score(xtest,ytest)\n",
    "print 'R square for RF: ', rsq1\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(ypred,ytest)\n",
    "plt.title(\"LASSO Regression\")\n",
    "plt.xlabel(\"fitted value\")\n",
    "plt.ylabel(\"actual value\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(pred_rf, ytest)\n",
    "plt.title(\"Random Forest Regression\")\n",
    "plt.xlabel(\"fitted value\")\n",
    "plt.ylabel(\"actual value\")\n",
    "\n",
    "\n",
    "#####################################\n",
    "#Find to 10 predictors\n",
    "#####################################\n",
    "indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "top10 = indices[0:10]\n",
    "\n",
    "f=[]\n",
    "for i in top10:\n",
    "    f.append(new_coeff_list[i])\n",
    "    \n",
    "    \n",
    "print f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of profitable movie, if gross is greater than budget\n",
      "------------Logistic regrassion  l2\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      1.00      1.00       896\\n        1.0       1.00      1.00      1.00       982\\n\\navg / total       1.00      1.00      1.00      1878\\n')\n",
      "------------Logistic regrassion  l1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schttrj1\\AppData\\Roaming\\Python\\Python27\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      1.00      1.00       896\\n        1.0       1.00      1.00      1.00       982\\n\\navg / total       1.00      1.00      1.00      1878\\n')\n",
      "------------Decision Tree method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.97      0.96      0.96       896\\n        1.0       0.96      0.97      0.97       982\\n\\navg / total       0.96      0.96      0.96      1878\\n')\n",
      "------------Extra Trees method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.87      0.86      0.86       896\\n        1.0       0.87      0.88      0.88       982\\n\\navg / total       0.87      0.87      0.87      1878\\n')\n",
      "------------Random Forest method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.92      0.90      0.91       896\\n        1.0       0.91      0.93      0.92       982\\n\\navg / total       0.91      0.91      0.91      1878\\n')\n",
      "------------GaussianNaiveBayes method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      0.05      0.10       896\\n        1.0       0.54      1.00      0.70       982\\n\\navg / total       0.76      0.55      0.41      1878\\n')\n",
      "------------Decision Tree method\n",
      "('vectorization Precision=', 0.87220525024923279)\n",
      "('vectorization Recall=', 0.90919588236739313)\n",
      "('vectorization F1=', 0.88581986097919008)\n",
      "------------Extra Trees method\n",
      "('vectorization Precision=', 0.88391710176533711)\n",
      "('vectorization Recall=', 0.8059749895585091)\n",
      "('vectorization F1=', 0.82451076854693928)\n",
      "------------Random Forest method\n",
      "('vectorization Precision=', 0.87759938044840169)\n",
      "('vectorization Recall=', 0.84417487654472656)\n",
      "('vectorization F1=', 0.85055675818876186)\n",
      "------------Logistic regrassion  l2\n",
      "('vectorization Precision=', 0.99900990099009912)\n",
      "('vectorization Recall=', 1.0)\n",
      "('vectorization F1=', 0.99950433705080532)\n",
      "------------Logistic regrassion  l1\n",
      "('vectorization Precision=', 0.99851850040949031)\n",
      "('vectorization Recall=', 0.99354838709677407)\n",
      "('vectorization F1=', 0.99575443748674619)\n",
      "------------GaussianNaiveBayes method\n",
      "('vectorization Precision=', 0.67159098011294682)\n",
      "('vectorization Recall=', 0.69925558312655078)\n",
      "('vectorization F1=', 0.59595137000484966)\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Logistic regrassion  l2\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.66      0.65      0.65       862\\n        1.0       0.71      0.72      0.71      1016\\n\\navg / total       0.69      0.69      0.69      1878\\n')\n",
      "------------Logistic regrassion  l1\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.68      0.69      0.69       862\\n        1.0       0.73      0.73      0.73      1016\\n\\navg / total       0.71      0.71      0.71      1878\\n')\n",
      "------------Decision Tree method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.63      0.61      0.62       862\\n        1.0       0.68      0.69      0.68      1016\\n\\navg / total       0.65      0.65      0.65      1878\\n')\n",
      "------------Extra Trees method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.62      0.69      0.65       862\\n        1.0       0.71      0.64      0.67      1016\\n\\navg / total       0.67      0.67      0.67      1878\\n')\n",
      "------------Random Forest method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.65      0.69      0.67       862\\n        1.0       0.72      0.68      0.70      1016\\n\\navg / total       0.69      0.69      0.69      1878\\n')\n",
      "------------GaussianNaiveBayes method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.54      0.36      0.43       862\\n        1.0       0.58      0.74      0.65      1016\\n\\navg / total       0.56      0.57      0.55      1878\\n')\n",
      "------------Decision Tree method\n",
      "('vectorization Precision=', 0.6525468702769347)\n",
      "('vectorization Recall=', 0.60967373412279202)\n",
      "('vectorization F1=', 0.64629009217137656)\n",
      "------------Extra Trees method\n",
      "('vectorization Precision=', 0.70865918189079902)\n",
      "('vectorization Recall=', 0.64777657666511068)\n",
      "('vectorization F1=', 0.67182699338092289)\n",
      "------------Random Forest method\n",
      "('vectorization Precision=', 0.73537684296828099)\n",
      "('vectorization Recall=', 0.62998181952190246)\n",
      "('vectorization F1=', 0.675525894651129)\n",
      "------------Logistic regrassion  l2\n",
      "('vectorization Precision=', 0.71451372166059102)\n",
      "('vectorization Recall=', 0.73175073090435594)\n",
      "('vectorization F1=', 0.71087549329196931)\n",
      "------------Logistic regrassion  l1\n",
      "('vectorization Precision=', 0.74438453106648983)\n",
      "('vectorization Recall=', 0.71681080018671839)\n",
      "('vectorization F1=', 0.72765460822749639)\n",
      "------------GaussianNaiveBayes method\n",
      "('vectorization Precision=', 0.66349573162989961)\n",
      "('vectorization Recall=', 0.56997518610421838)\n",
      "('vectorization F1=', 0.53875146685726194)\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of profitable movie, if gross is greater than budget\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):    \n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'gross'\n",
    "list_fig = ['director_facebook_likes','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "y = data['profit']\n",
    "print(\"Classification of profitable movie, if gross is greater than budget\")\n",
    "\n",
    "cut_off = 0\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "# Adding text features\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x_all, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of High rated movie, if IMDB rating greater than 8\n",
      "------------Logistic regrassion  l2\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.95      0.99      0.97      1775\\n        1.0       0.57      0.12      0.19       103\\n\\navg / total       0.93      0.95      0.93      1878\\n')\n",
      "------------Logistic regrassion  l1\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      1.00      1.00      1775\\n        1.0       0.99      0.92      0.95       103\\n\\navg / total       1.00      1.00      1.00      1878\\n')\n",
      "------------Decision Tree method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      1.00      1.00      1775\\n        1.0       1.00      1.00      1.00       103\\n\\navg / total       1.00      1.00      1.00      1878\\n')\n",
      "------------Extra Trees method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.98      1.00      0.99      1775\\n        1.0       0.95      0.60      0.74       103\\n\\navg / total       0.98      0.98      0.97      1878\\n')\n",
      "------------Random Forest method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       1.00      1.00      1.00      1775\\n        1.0       1.00      1.00      1.00       103\\n\\navg / total       1.00      1.00      1.00      1878\\n')\n",
      "------------GaussianNaiveBayes method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.96      0.96      0.96      1775\\n        1.0       0.25      0.25      0.25       103\\n\\navg / total       0.92      0.92      0.92      1878\\n')\n",
      "------------Decision Tree method\n",
      "('vectorization Precision=', 1.0)\n",
      "('vectorization Recall=', 1.0)\n",
      "('vectorization F1=', 1.0)\n",
      "------------Extra Trees method\n",
      "('vectorization Precision=', 0.95823529411764707)\n",
      "('vectorization Recall=', 0.70155038759689925)\n",
      "('vectorization F1=', 0.81435718619280251)\n",
      "------------Random Forest method\n",
      "('vectorization Precision=', 1.0)\n",
      "('vectorization Recall=', 1.0)\n",
      "('vectorization F1=', 0.99759036144578306)\n",
      "------------Logistic regrassion  l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Python27\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vectorization Precision=', 0.47000000000000003)\n",
      "('vectorization Recall=', 0.10265780730897012)\n",
      "('vectorization F1=', 0.14516038711042739)\n",
      "------------Logistic regrassion  l1\n",
      "('vectorization Precision=', 0.9507996068971678)\n",
      "('vectorization Recall=', 0.91539313399778521)\n",
      "('vectorization F1=', 0.92466629790323418)\n",
      "------------GaussianNaiveBayes method\n",
      "('vectorization Precision=', 0.32887901572112099)\n",
      "('vectorization Recall=', 0.32314507198228132)\n",
      "('vectorization F1=', 0.24392397408261948)\n",
      "-----------------------Numerical + categorical features----------------------------------------\n",
      "------------Logistic regrassion  l2\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.97      0.94      0.95      1764\\n        1.0       0.34      0.50      0.40       114\\n\\navg / total       0.93      0.91      0.92      1878\\n')\n",
      "------------Logistic regrassion  l1\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.98      0.99      0.99      1764\\n        1.0       0.85      0.70      0.77       114\\n\\navg / total       0.97      0.97      0.97      1878\\n')\n",
      "------------Decision Tree method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.97      0.97      0.97      1764\\n        1.0       0.55      0.54      0.54       114\\n\\navg / total       0.94      0.95      0.95      1878\\n')\n",
      "------------Extra Trees method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.95      1.00      0.98      1764\\n        1.0       0.90      0.24      0.38       114\\n\\navg / total       0.95      0.95      0.94      1878\\n')\n",
      "------------Random Forest method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.96      1.00      0.98      1764\\n        1.0       0.87      0.30      0.44       114\\n\\navg / total       0.95      0.95      0.94      1878\\n')\n",
      "------------GaussianNaiveBayes method\n",
      "('Classification Report:\\n', '             precision    recall  f1-score   support\\n\\n        0.0       0.97      0.96      0.96      1764\\n        1.0       0.46      0.57      0.51       114\\n\\navg / total       0.94      0.93      0.94      1878\\n')\n",
      "------------Decision Tree method\n",
      "('vectorization Precision=', 0.47328095681152238)\n",
      "('vectorization Recall=', 0.53687707641196014)\n",
      "('vectorization F1=', 0.51253816424330201)\n",
      "------------Extra Trees method\n",
      "('vectorization Precision=', 0.83825825825825828)\n",
      "('vectorization Recall=', 0.31495016611295679)\n",
      "('vectorization F1=', 0.39400940072067758)\n",
      "------------Random Forest method\n",
      "('vectorization Precision=', 0.85897563133083776)\n",
      "('vectorization Recall=', 0.35304540420819491)\n",
      "('vectorization F1=', 0.44712681546521482)\n",
      "------------Logistic regrassion  l2\n",
      "('vectorization Precision=', 0.54619935348209514)\n",
      "('vectorization Recall=', 0.53089700996677736)\n",
      "('vectorization F1=', 0.40026118307644359)\n",
      "------------Logistic regrassion  l1\n",
      "('vectorization Precision=', 0.79386363636363633)\n",
      "('vectorization Recall=', 0.62569213732004436)\n",
      "('vectorization F1=', 0.67244986986488342)\n",
      "------------GaussianNaiveBayes method\n",
      "('vectorization Precision=', 0.48970078262576139)\n",
      "('vectorization Recall=', 0.59191583610188259)\n",
      "('vectorization F1=', 0.46352796632081877)\n"
     ]
    }
   ],
   "source": [
    "# Author: Sayma Akther\n",
    "# Classification of High rated movie, if IMDB rating greater than 8\n",
    "\n",
    "import pandas\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LassoLarsIC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, preprocessing, cross_validation\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import Preprocessor\n",
    "import Evaluator\n",
    "\n",
    "\n",
    "def numerical_to_binary(y, cut_off):\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v < cut_off]]=0\n",
    "\ty.iloc[[i for i,v in enumerate(y) if v >= cut_off]]=1\n",
    "\treturn y\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "def scaler(data,target):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    target = pd.DataFrame(scaler.fit_transform(target))\n",
    "    return data,target\n",
    "\n",
    "\n",
    "data = pandas.read_csv('movie_metadata.csv')\n",
    "features_allnum = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'imdb_score', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "features_x = ['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_1_facebook_likes', 'gross', 'num_user_for_reviews', 'budget', 'title_year', 'aspect_ratio', 'movie_facebook_likes']\n",
    "feature_y = 'imdb_score'\n",
    "list_fig = ['director_facebook_likes','gross','num_voted_users','num_critic_for_reviews','num_user_for_reviews','budget',\\\n",
    "            'movie_facebook_likes','duration','actor_3_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\\\n",
    "           'cast_total_facebook_likes','facenumber_in_poster','profit']\n",
    "data = Preprocessor.data\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "\n",
    "x, y = Preprocessor.getX_y(feature_y, features_allnum)\n",
    "# x,y = scaler(x,y)\n",
    "print(\"Classification of High rated movie, if IMDB rating greater than 8\")\n",
    "\n",
    "cut_off = 8\n",
    "y=numerical_to_binary(y, cut_off)\n",
    "Evaluator.evaluateClassification(x, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x, y)\n",
    "\n",
    "\n",
    "# Adding text features\n",
    "print('-----------------------Numerical + categorical features----------------------------------------')\n",
    "vectorizer = TfidfVectorizer(tokenizer=token)\n",
    "genre = vectorizer.fit_transform(data['genres'])\n",
    "genres_list = [\"genres_\"+ i for i in vectorizer.get_feature_names()]\n",
    "\n",
    "vectorizer_pk = TfidfVectorizer(max_features=50,tokenizer=token)\n",
    "pk = vectorizer_pk.fit_transform(data['plot_keywords'])\n",
    "pk_list = [\"pk_\"+ i for i in vectorizer_pk.get_feature_names()]\n",
    "\n",
    "vectorizer_c = TfidfVectorizer()\n",
    "c = vectorizer_c.fit_transform(data['country'])\n",
    "c_list = [\"c_\"+ i for i in vectorizer_c.get_feature_names()]\n",
    "\n",
    "x_all = np.hstack([data.ix[:,list_fig],genre.todense(),pk.todense(),c.todense()])\n",
    "\n",
    "Evaluator.evaluateClassification(x_all, y, 0.5)\n",
    "Evaluator.crossvalidationClassification(x_all, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
